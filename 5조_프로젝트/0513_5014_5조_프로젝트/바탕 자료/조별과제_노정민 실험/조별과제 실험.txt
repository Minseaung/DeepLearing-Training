조건
1. 사기데이터=1968
2. 정상데이터=1000
>>조건 1,2 가정 한 이유는 초기의 데이터는 28만여개의 데이터가 사기꾼 데이터에 비해
정상데이터의 비중이 너무 높아 어떠한 값을 넣어도 정확도가 거의 100%가 나오기 때문에
사기꾼 데이터는 늘리고 정상 데이터는 대폭 줄여 
오히려 사기꾼 데이터가 더 많아지게 값을 주어 보았다. 

3. 모델은 같다(v1=v2=v3)

v1, v2 조건: batch_size=100 일때
똑같은 값으로 다시 돌렸는데 다르게 나온다??무슨 뜻인가요??
데이터 갯수가 작아서 값이 다르게 나오는 것???


v3 조건: batch_size=32만 바꾼것

결론: 그래프만 보자면 뭔가 이쁜 그래프인것처럼 보이나 내 지식으론 잘 모르겠다
     확실한 건 데이터 수와 모델값을 계속 바꾸는 실험을 해보는 것이 답이지만
      그전에 내 머리가 터질 수 있을거 같다.
